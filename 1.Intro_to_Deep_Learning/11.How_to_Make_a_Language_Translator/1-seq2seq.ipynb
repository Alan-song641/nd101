{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据论文[Sutskever, Vinyals and Le (2014)](https://arxiv.org/abs/1409.3215)而来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看图：\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/April/58e5893b_sequence-to-sequence-unrolled-encoder-decoder/sequence-to-sequence-unrolled-encoder-decoder.png)\n",
    "在实际的word2word中，我们会对单词进行embedding操作，此处为了简单起见，我们直接就以数字代表输入了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [[5, 7, 8], [6, 3], [3], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, xlen = helper.batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6, 3, 1],\n",
       "       [7, 3, 0, 0],\n",
       "       [8, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt # [max_time_len, batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在处理中，我们会做一些特殊的处理\n",
    "\n",
    "1. < PAD>: 在训练过程中，batch中每个句子长度会不同了，此时我们对于短的就直接用 < PAD> 来填充的\n",
    "2. < EOS>: EOS代表的句子的结尾\n",
    "3. < UNK>: 对于一些不常见的词汇，直接用UNK替换掉（例如人名）\n",
    "4. < GO>: decode的第一个输入，告诉decode预测开始\n",
    "\n",
    "## 定义模型\n",
    "在定义模型的时候，我们需要确定的是 vocab_size ， input_embedding_size 和 encoder_hidden_units 和 decoder_hidden_units ，一旦修改得重新定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "# UNK = 2\n",
    "# GO  = 3\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个复杂的模型，我们想要去了解他，最好的方式就是看输入和输出，seq2seq的模型其输入和输出是：\n",
    "\n",
    "- encoder_inputs int32 tensor is shaped [encoder_max_time, batch_size]\n",
    "- decoder_targets int32 tensor is shaped [decoder_max_time, batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还需要定义的一个输入是decoder的输入\n",
    "- decoder_inputs int32 tensor is shaped [decoder_max_time, batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型训练的时候，对于decoder的ouputs我们不会使用，而是直接使用decoder_targets作为decoder的输入，但是在做predictions的时候，我们却会使用decoder的输出作为下一个lstm的输入，这可能会引入 distribution shift from training to prediction.\n",
    "\n",
    "## Embeddings\n",
    "我们系统的输入encoder_inputs和decoder_inputs都是 [decoder_max_time, batch_size]的形状，但是我们 encoder 和 decoder 的输入形状都是要 [max_time, batch_size, input_embedding_size]， 因此我们需要对我们的是输入做一个word embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.truncated_normal([vocab_size, input_embedding_size], mean=0.0, stddev=0.1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(?, ?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_inputs_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.BasicLSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layers = 4\n",
    "cell = tf.contrib.rnn.MultiRNNCell([encoder_cell] * lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If `time_major == True`, this must be a `Tensor` of shape:\n",
    "#       `[max_time, batch_size, ...]`, or a nested tuple of such\n",
    "#       elements.\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(cell,encoder_inputs_embedded,dtype=tf.float32,time_major=True)\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处我们直接删除了 encoder_outputs， 因为在这个场景中我们是不关注的，我们需要的是最后的 encoder_final_state，这又被称为 \"thought vector\"，如果没有引入attention机制，encoder_final_state 就是decoder的唯一输入，用他来作为decoder的init_state来解出decoder_targets。\n",
    "\n",
    ">We hope that backpropagation through time (BPTT) algorithm will tune the model to pass enough information throught the thought vector for correct sequence output decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 20) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(?, 20) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_6:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_7:0' shape=(?, 20) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_8:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_9:0' shape=(?, 20) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "print(encoder_final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.BasicLSTMCell(decoder_hidden_units)\n",
    "decoder = tf.contrib.rnn.MultiRNNCell([decoder_cell] * lstm_layers)\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder, decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处我们不关心decoder_inputs，而是关心decoder_outputs，对于decoder_outputs我们加一个fc，active_function=softmax，得到预测的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.fully_connected(decoder_outputs,vocab_size,activation_fn=None,\n",
    "                                              weights_initializer = tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                              biases_initializer=tf.zeros_initializer())\n",
    "# decoder_prediction = tf.argmax(decoder_logits,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"fully_connected/Reshape_1:0\", shape=(?, ?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits,2) # 在这一步我突然意识到了axis的含义。。。表明的竟然是在哪个维度上求 argmax。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax:0\", shape=(?, ?), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于RNN的输出，其shape是：[max_time, batch_size, hidden_units]，通过一个FC，将其映射为：[max_time, batch_size, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learn_rate = tf.placeholder(tf.float32)\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 试运行\n",
    ">deep learning is a game of shapes\n",
    "\n",
    "当我们build graph的时候，如果shape错误就马上会提示，但是一些其他的shape检查，只有我们运行的时候才会发现错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_encoded:\n",
      "[[6 3 9]\n",
      " [0 4 8]\n",
      " [0 0 7]]\n",
      "decoder inputs:\n",
      "[[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "decoder predictions:\n",
      "[[9 6 6]\n",
      " [9 6 2]\n",
      " [9 6 2]\n",
      " [9 9 4]]\n",
      "build graph ok!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_ = [[6], [3, 4], [9, 8, 7]]\n",
    "\n",
    "    batch_, batch_length_ = helper.batch(batch_)\n",
    "    print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "    din_, dlen_ = helper.batch(np.ones(shape=(3, 1), dtype=np.int32),\n",
    "                                max_sequence_length=4)\n",
    "    print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "    pred_ = sess.run(decoder_prediction,\n",
    "        feed_dict={\n",
    "            encoder_inputs: batch_,\n",
    "            decoder_inputs: din_,\n",
    "#             learn_rate:0.1,\n",
    "        })\n",
    "    print('decoder predictions:\\n' + str(pred_))\n",
    "    \n",
    "print(\"build graph ok!\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模拟训练\n",
    "我们为了简单起见，产生了随机的输入序列，然后decoder原模原样的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[7, 2, 9, 2, 2, 4, 4]\n",
      "[6, 9, 8, 5, 2, 3]\n",
      "[9, 3, 2, 4, 7]\n",
      "[2, 5, 3, 3, 6, 8, 9]\n",
      "[2, 4, 8, 5, 5, 3]\n",
      "[2, 6, 3]\n",
      "[3, 5, 2, 2]\n",
      "[9, 5, 3]\n",
      "[8, 5, 4, 2]\n",
      "[4, 9, 5, 2, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helper.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, _ = helper.batch(batch)\n",
    "    decoder_targets_, _ = helper.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, _ = helper.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当encoder_inputs 是[5, 6, 7]是decoder_targets是 [5, 6, 7, 1],1代表的是EOF，decoder_inputs则是 [1, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.301229476928711\n",
      "  sample 1:\n",
      "    input     > [4 8 3 3 4 8 0 0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 8 7 8 4 3 0 0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 4 3 0 0 0 0 0]\n",
      "    predicted > [6 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.958212673664093\n",
      "  sample 1:\n",
      "    input     > [7 2 6 8 0 0 0 0]\n",
      "    predicted > [7 7 3 3 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 6 8 6 3 8 0 0]\n",
      "    predicted > [3 3 6 6 6 6 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 2 4 4 0 0 0 0]\n",
      "    predicted > [5 4 4 4 1 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.3982703983783722\n",
      "  sample 1:\n",
      "    input     > [8 7 8 0 0 0 0 0]\n",
      "    predicted > [8 7 8 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 7 9 5 3 0 0 0]\n",
      "    predicted > [3 7 8 5 9 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 8 9 2 0 0 0 0]\n",
      "    predicted > [2 3 9 2 1 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.27779871225357056\n",
      "  sample 1:\n",
      "    input     > [3 4 5 4 3 8 4 0]\n",
      "    predicted > [3 4 4 5 3 2 4 1 0]\n",
      "  sample 2:\n",
      "    input     > [5 4 6 3 8 0 0 0]\n",
      "    predicted > [5 4 6 3 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 7 6 0 0 0 0 0]\n",
      "    predicted > [4 7 6 1 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        for batch in range(max_batches):\n",
    "            fd = next_feed()\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print()\n",
    "    except KeyboardInterrupt:\n",
    "        print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.2582 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQdSchcRcaD/B4CzY7PBz9SlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1175e1f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
