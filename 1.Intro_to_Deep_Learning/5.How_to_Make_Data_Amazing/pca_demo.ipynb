{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐好文[PCA的数学原理](http://blog.codinglabs.org/articles/pca-tutorial.html)\n",
    "本文将会用Python来实现PCA，帮助更好的理解\n",
    "\n",
    "## 1. 获取数据\n",
    "我们用的数据是150个鸢尾花，然后通过4个维度刻画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "    header=None, \n",
    "    sep=',')\n",
    "\n",
    "df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "df.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.ix[:,0:4].values\n",
    "y = df.ix[:,4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在上面数据处理后，x是一个150 * 4 的矩阵，每一行都是一个样本，y是一个 150 * 1 是向量，每个都是一个分类\n",
    "\n",
    "我们下一步是来看3类型的花怎么分布在4个特征上，我们可以通过直方图来展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfuly sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~zhuanxuhit/0 or inside your plot.ly account where it is named 'basic-line'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~zhuanxuhit/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting histograms\n",
    "tls.set_credentials_file(username='zhuanxuhit', api_key='30dCVmghG2CqKQqfSzsu')\n",
    "\n",
    "traces = []\n",
    "\n",
    "legend = {0:False, 1:False, 2:False, 3:True}\n",
    "\n",
    "colors = {'Iris-setosa': 'rgb(31, 119, 180)', \n",
    "          'Iris-versicolor': 'rgb(255, 127, 14)', \n",
    "          'Iris-virginica': 'rgb(44, 160, 44)'}\n",
    "\n",
    "for col in range(4):\n",
    "    for key in colors:\n",
    "        traces.append(Histogram(x=X[y==key, col], \n",
    "                        opacity=0.75,\n",
    "                        xaxis='x%s' %(col+1),\n",
    "                        marker=Marker(color=colors[key]),\n",
    "                        name=key,\n",
    "                        showlegend=legend[col]))\n",
    "\n",
    "data = Data(traces)\n",
    "\n",
    "layout = Layout(barmode='overlay',\n",
    "                xaxis=XAxis(domain=[0, 0.25], title='sepal length (cm)'),\n",
    "                xaxis2=XAxis(domain=[0.3, 0.5], title='sepal width (cm)'),\n",
    "                xaxis3=XAxis(domain=[0.55, 0.75], title='petal length (cm)'),\n",
    "                xaxis4=XAxis(domain=[0.8, 1], title='petal width (cm)'),\n",
    "                yaxis=YAxis(title='count'),\n",
    "                title='Distribution of the different Iris flower features')\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename = 'basic-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 规范化\n",
    "我们将数据转化为 mean=0 and variance=1 的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.73695157e-16,  -6.63173220e-16,   3.31586610e-16,\n",
       "        -2.84217094e-16])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mean_vec = X_std.mean(axis=0)\n",
    "mean_vec # 均值为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std.std(axis=0) # 方差为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获得原矩阵的信息\n",
    "scaler = StandardScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.84333333,  3.054     ,  3.75866667,  1.19866667])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82530129,  0.43214658,  1.75852918,  0.76061262])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_scale = scaler.transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.mean(x_scale,axis=0) # 均值为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征分解\n",
    "下一步我们就做PCA的核心：计算特征值和特征向量\n",
    "列举下目前我们的状态\n",
    "\n",
    "1. 我们有150个4维的数据，组成了 4 * 150的矩阵 X\n",
    "2. 假设 C = 1/150 * X * T(X), 则C是一个对称矩阵，而且是 4 * 4 的，其对角是各个字段的方差，而第i行j列和j行i列元素相同，表示i和j两个字段的协方差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale = X_std.T\n",
    "X_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix \n",
      "[[ 1.         -0.10936925  0.87175416  0.81795363]\n",
      " [-0.10936925  1.         -0.4205161  -0.35654409]\n",
      " [ 0.87175416 -0.4205161   1.          0.9627571 ]\n",
      " [ 0.81795363 -0.35654409  0.9627571   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cov_mat = X_scale.dot(X_scale.T)/X_scale.shape[1]\n",
    "print('Covariance matrix \\n%s' %cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy covariance matrix: \n",
      "[[ 1.00671141 -0.11010327  0.87760486  0.82344326]\n",
      " [-0.11010327  1.00671141 -0.42333835 -0.358937  ]\n",
      " [ 0.87760486 -0.42333835  1.00671141  0.96921855]\n",
      " [ 0.82344326 -0.358937    0.96921855  1.00671141]]\n"
     ]
    }
   ],
   "source": [
    "print('NumPy covariance matrix: \\n%s' %np.cov(X_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着我们计算协方差矩阵cov_mat的特征值和特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors \n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "\n",
      "Eigenvalues \n",
      "[ 2.91081808  0.92122093  0.14735328  0.02060771]\n"
     ]
    }
   ],
   "source": [
    "cov_mat = X_scale.dot(X_scale.T)/X_scale.shape[1]\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# eig_vecs.T.dot(cov_mat).dot(eig_vecs) = eig_vals 对象矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以通过其他命令一次性就获取特征向量和特征值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors \n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "\n",
      "Eigenvalues \n",
      "[ 2.91081808  0.92122093  0.14735328  0.02060771]\n"
     ]
    }
   ],
   "source": [
    "cor_mat2 = np.corrcoef(X.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择主成分\n",
    "现在我们有了特征向量，特征向量中的每一个都可以认为是单位长度为1的基，我们来验证下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      "[-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      "[ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      "[ 0.56561105 -0.06541577  0.6338014   0.52354627]\n",
      "Everything ok!\n"
     ]
    }
   ],
   "source": [
    "for ev in eig_vecs:\n",
    "    print(ev)\n",
    "    np.testing.assert_array_almost_equal(1.0,\n",
    "                                         np.linalg.norm(ev))\n",
    "print('Everything ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999999922"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(( eig_vecs[0] )**2) # np.linalg.norm 范数  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在有4个向量基，下一步要确定的是哪个方向上投影后能够让方差最大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order:\n",
      "2.91081808375\n",
      "0.921220930707\n",
      "0.147353278305\n",
      "0.0206077072356\n"
     ]
    }
   ],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解释方差\n",
    "分析完信息最多的投影方向后，下面就是要决定我们要选择多少个投影基来投影了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72.770452093801353,\n",
       " 23.030523267680632,\n",
       " 3.6838319576273935,\n",
       " 0.51519268089062353]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = sum(eig_vals) # 所有特征值的和\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)] # 每个特征值的百分比\n",
    "var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  72.77045209,   95.80097536,   99.48480732,  100.        ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_var_exp = np.cumsum(var_exp) # 计算累计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~zhuanxuhit/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "trace1 = Bar(\n",
    "        x=['PC %s' %i for i in range(1,5)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,5)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Explained variance by different principal components')\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图可以显示出：PC1的贡献最大\n",
    "## 投影矩阵\n",
    "投影矩阵就是我们之前计算出来的特征矩阵，选择前两个多的特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors \n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "\n",
      "Eigenvalues \n",
      "[ 2.91081808  0.92122093  0.14735328  0.02060771]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.91081808e+00,   0.00000000e+00,   6.66133815e-16,\n",
       "          7.77156117e-16],\n",
       "       [  8.32667268e-17,   9.21220931e-01,  -4.16333634e-16,\n",
       "          1.94289029e-16],\n",
       "       [  5.82867088e-16,  -4.02455846e-16,   1.47353278e-01,\n",
       "         -2.08166817e-17],\n",
       "       [  9.26342336e-16,   1.94505870e-16,  -4.07660017e-17,\n",
       "          2.06077072e-02]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_mat2 = np.corrcoef(X.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "\n",
    "eig_vecs.T.dot(cov_mat).dot(eig_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[ 0.52237162 -0.26335492  0.58125401  0.56561105]\n",
      " [-0.37231836 -0.92555649 -0.02109478 -0.06541577]]\n"
     ]
    }
   ],
   "source": [
    "# 此时我们的投影矩阵 P = eig_vecs.T\n",
    "P = eig_vecs.T\n",
    "matrix_w = P[[0,1]]\n",
    "print('Matrix W:\\n', matrix_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 映射到新的2维空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = matrix_w.dot(X_std.T).T\n",
    "# Y 每一行代表一个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~zhuanxuhit/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces = []\n",
    "\n",
    "for name in ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'):\n",
    "\n",
    "    trace = Scatter(\n",
    "        x=Y[y==name,0],\n",
    "        y=Y[y==name,1],\n",
    "        mode='markers',\n",
    "        name=name,\n",
    "        marker=Marker(\n",
    "            size=12,\n",
    "            line=Line(\n",
    "                color='rgba(217, 217, 217, 0.14)',\n",
    "                width=0.5),\n",
    "            opacity=0.8))\n",
    "    traces.append(trace)\n",
    "\n",
    "\n",
    "data = Data(traces)\n",
    "layout = Layout(showlegend=True,\n",
    "                scene=Scene(xaxis=XAxis(title='PC1'),\n",
    "                yaxis=YAxis(title='PC2'),))\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们自己一步一步的实现了PCA，达到了降维度的目的，我们可以使用scikit-learn中的方法快速的实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~zhuanxuhit/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces = []\n",
    "\n",
    "for name in ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'):\n",
    "\n",
    "    trace = Scatter(\n",
    "        x=Y_sklearn[y==name,0],\n",
    "        y=Y_sklearn[y==name,1],\n",
    "        mode='markers',\n",
    "        name=name,\n",
    "        marker=Marker(\n",
    "            size=12,\n",
    "            line=Line(\n",
    "                color='rgba(217, 217, 217, 0.14)',\n",
    "                width=0.5),\n",
    "            opacity=0.8))\n",
    "    traces.append(trace)\n",
    "\n",
    "\n",
    "data = Data(traces)\n",
    "layout = Layout(xaxis=XAxis(title='PC1', showline=False),\n",
    "                yaxis=YAxis(title='PC2', showline=False))\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "最后我们来总结下整个过程：\n",
    "![](http://bos.nj.bpc.baidu.com/v1/agroup/1471c8f02c95a17b0f9f5239dae5d5cf33b2d586)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
